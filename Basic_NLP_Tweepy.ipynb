{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic NLP - Praktek Scraping Tweet__\n",
    "<br>\n",
    "\n",
    "oleh:<br>\n",
    "__Ibnu Pujiono__<br>\n",
    "__Sigit Sumarsono__<br>\n",
    "\n",
    "_Ministry of Finance Data Analytics Community (MoF-DAC)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kali ini kita akan mencoba melakukan praktek scraping pada twitter menggunakan bantuan library Tweepy. Dokumentasi [Tweepy](https://docs.tweepy.org/en/stable/).\n",
    "\n",
    "<details>\n",
    "    <img src=\"img/tweepy.jpeg\">\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proses Scraping pada Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installasi Library Tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perintah yang dilakukan untuk melakukan proses installasi library ```Tweepy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T13:04:47.756672Z",
     "start_time": "2021-10-28T13:04:46.170207Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library dan Inisiasi Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini kita harus mengakses dashboard Twitter for Developer yang sudah kita miliki lalu memasukkan ```consumer key``` dan juga ```access token``` untuk mendapatkan otorisasi akses.\n",
    "<details>\n",
    "    <img src=\"img/tweepy-2.jpeg\">\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:20:12.063510Z",
     "start_time": "2021-10-28T15:20:12.058276Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "consumer_key = '(isi dengan token masing-masing)'\n",
    "consumer_secret = '(isi dengan token masing-masing)'\n",
    "access_token = '(isi dengan token masing-masing)'\n",
    "access_token_secret = '(isi dengan token masing-masing)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proses inisialisai Tweepy menggunakan token yang sudah kita miliki dilakukan dengan fungsi ```AuthHandler```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:20:14.784243Z",
     "start_time": "2021-10-28T15:20:14.777207Z"
    }
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ini berhasil kita baru dapat melakukan proses scraping pada twitter menggunakan akun kita masing-masing. Let's try it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:21:53.008594Z",
     "start_time": "2021-10-28T15:21:52.990689Z"
    }
   },
   "outputs": [],
   "source": [
    "dir(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengambil Tweet dari Akun Tertentu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kita dapat mengambil tweet dari timeline akun pribadi kita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:20:19.040448Z",
     "start_time": "2021-10-28T15:20:18.758409Z"
    }
   },
   "outputs": [],
   "source": [
    "mytimeline = api.home_timeline()\n",
    "for tweet in mytimeline:\n",
    "   print (tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kita juga dapat mengambil tweet dari akun tertentu yang kita kehendaki, contoh disini adalah dari akun ```@kompascom```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:20:21.701077Z",
     "start_time": "2021-10-28T15:20:21.355080Z"
    }
   },
   "outputs": [],
   "source": [
    "nama = \"kompascom\"\n",
    "jumlahtweet = 20\n",
    "\n",
    "tweets = api.user_timeline(id=nama, count=jumlahtweet)\n",
    "\n",
    "for tweet in tweets:\n",
    "   print (tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat Trending Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat melihat ```Trending Topic``` Twitter dari sebuah lokasi menggunakan woe_id, The Yahoo! Where On Earth ID  atau woe_id merupakan kode lokasi dari Yahoo. Daftar WOE_ID dapat dilihat di [link](https://gist.github.com/edsu/a5f6c1188ec3a27d38634721fb25fffb) ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:27:02.029517Z",
     "start_time": "2021-10-28T15:27:01.703897Z"
    }
   },
   "outputs": [],
   "source": [
    "#Melihat Trending Topic di Indonesia\n",
    "indonesia_woe = 23424846\n",
    "\n",
    "trends = api.trends_place(indonesia_woe)\n",
    "print(trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T14:11:55.783353Z",
     "start_time": "2021-10-28T14:11:55.762851Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Melihat Trending Topic di Newyork\n",
    "newyorkwoe = 23424977\n",
    "trends_ny = api.trends_place(newyorkwoe)\n",
    "#Melihat isi dari Trending Topic\n",
    "for item in (trends_ny[0]['trends']):\n",
    "       print (item['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:20:55.644176Z",
     "start_time": "2021-10-28T15:20:55.630404Z"
    }
   },
   "outputs": [],
   "source": [
    "#Melihat isi dari Trending Topic\n",
    "for item in (trends[0]['trends']):\n",
    "       print (item['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita juga dapat mengambil ```jumlah tweet``` dari trending topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:21:05.885309Z",
     "start_time": "2021-10-28T15:21:05.876536Z"
    }
   },
   "outputs": [],
   "source": [
    "for item in (trends[0]['trends']):\n",
    "       print(item['tweet_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita juga dapat membuat dataframe yang berisi ```Trending Topic``` dan ```Jumlah Tweet Trending Topic```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:21:08.588456Z",
     "start_time": "2021-10-28T15:21:08.576638Z"
    }
   },
   "outputs": [],
   "source": [
    "#Membuat List Trending Topic\n",
    "name = []\n",
    "for item in (trends[0]['trends']):\n",
    "       name.append(item['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:42.615805Z",
     "start_time": "2021-10-28T10:13:42.601842Z"
    }
   },
   "outputs": [],
   "source": [
    "#Membuat List Jumlah Tweet\n",
    "volume = []\n",
    "for item in (trends[0]['trends']):\n",
    "       volume.append(item['tweet_volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:21:12.491052Z",
     "start_time": "2021-10-28T15:21:12.470618Z"
    }
   },
   "outputs": [],
   "source": [
    "#Membuat Dataframe\n",
    "df_trend = pd.DataFrame({'TrendingTopic': name,\n",
    "                   'Volume' : volume})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:42.647721Z",
     "start_time": "2021-10-28T10:13:42.632760Z"
    }
   },
   "outputs": [],
   "source": [
    "df_trend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu kita lakukan visualisasi sederhana menggunakan barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:43.697174Z",
     "start_time": "2021-10-28T10:13:42.649715Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plot = sns.barplot(data=df_trend[:10], x=\"TrendingTopic\", y=\"Volume\")\n",
    "plt.title(\"Jumlah Tweet 10 Trending Topic Teratas\")\n",
    "for item in plot.get_xticklabels():\n",
    "    item.set_rotation(75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Menggunakan Keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat juga mencari tweet tertentu dengan menggunakan keyword yang kita tentukan sendiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T15:21:17.581596Z",
     "start_time": "2021-10-28T15:21:17.572597Z"
    }
   },
   "outputs": [],
   "source": [
    "#Mencari Kata Tertentu\n",
    "search_words = \"sumpah pemuda\"\n",
    "date_since = \"2021-10-21\"\n",
    "date_until = \"2021-10-28\"\n",
    "new_search = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "        q=new_search,\n",
    "        lang=\"id\",\n",
    "        since=date_since,\n",
    "        until=date_until).items(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:53.709614Z",
     "start_time": "2021-10-28T10:13:43.712871Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "items = []\n",
    "for tweet in tweets:\n",
    "  items.append (' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet.text).split()))\n",
    "  hasil_scrape = pd.DataFrame(data=items, columns=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:53.724572Z",
     "start_time": "2021-10-28T10:13:53.710544Z"
    }
   },
   "outputs": [],
   "source": [
    "hasil_scrape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Deskriptif Sederhana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung Banyak Kata yang muncul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kita cleansing data seperti yang sudah kita lakukan sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:59.863127Z",
     "start_time": "2021-10-28T10:13:53.725505Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "#Proses Pembersihan Data\n",
    "#Import Library\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "#Bersihin data pake NLTK\n",
    "#1. Kecilin Huruf\n",
    "hasil = [item.lower() for item in hasil_scrape.tweet]\n",
    "#2. Menghilangkan angka, alamat htpp, tanda baca, whitespace\n",
    "hasil = [' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", item).split()) for item in hasil]\n",
    "hasil = [' '.join(re.sub(r\"\\d+\", \"\", item).split()) for item in hasil]\n",
    "from nltk.corpus import stopwords\n",
    "data = []\n",
    "stopwords = set(stopwords.words('indonesian'))\n",
    "for item in hasil:\n",
    "  querywords = item.split()\n",
    "  resultwords  = [word for word in querywords if word not in stopwords]\n",
    "  result = ' '.join(resultwords)\n",
    "  data.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sebelum dimasukkan perlu dilakukan cleansing ulang dengan memasukkan data ke dalam list dan membuat token kata dalam satu list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:59.910963Z",
     "start_time": "2021-10-28T10:13:59.864092Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "data = [word_tokenize(item) for item in data]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:59.926920Z",
     "start_time": "2021-10-28T10:13:59.912959Z"
    }
   },
   "outputs": [],
   "source": [
    "data = list(itertools.chain(*data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Selanjutnya kita dapat melihat banyaknya kata yang muncul dari tweet yang sudah kita scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:13:59.942879Z",
     "start_time": "2021-10-28T10:13:59.928916Z"
    }
   },
   "outputs": [],
   "source": [
    "fqdist = FreqDist(data)\n",
    "print(fqdist.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:14:00.242116Z",
     "start_time": "2021-10-28T10:13:59.944874Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "fig,ax = plt.subplots()\n",
    "fqdist.plot(15,cumulative=False)\n",
    "plt.show()\n",
    "fig.savefig('Grafik Kata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sebelum membuat wordcloud kita perlu melakukan installasi library Wordcloud. Dokumentasi dapat dilihat pada [link](http://amueller.github.io/word_cloud/) ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:14:04.101761Z",
     "start_time": "2021-10-28T10:14:00.245072Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T10:14:04.908599Z",
     "start_time": "2021-10-28T10:14:04.103753Z"
    }
   },
   "outputs": [],
   "source": [
    "#Membuat Wordcloud dari Tweet yang sudah discrape\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "data_ok = ' '.join(data)\n",
    "wordcloud = WordCloud(width=1600, height=1000, max_font_size=200, max_words=30,background_color='white').generate(data_ok)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Wordcloud Keyword Sumpah Pemuda\",size=30)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "themify": {
   "theme": "MOF-DAC 2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
